modifier - modifier le code - voir Wikidata (aide)
LLaMA (Large Language Model Meta AI) est un grand modèle linguistique développé par Meta et rendu publiquement accessible. Deux autres versions du modèle plus spécifiques, optimisées à partir de LLaMA, ont également été publiées par Meta : un agent conversationnel, appelé Llama Chat, et un assistant de programmation, Code Llama. D'autres modèles de langage comme Alpaca ont également vu le jour en entrainant les poids de Llama sur de nouvelles données.
LLaMA est l'acronyme de Large Language Model Meta AI (Grand modèle de Language Meta IA en français). Cet acronyme est l'homographe du nom anglais (lui-même emprunté au quechua, via l'espagnol) du lama, un camélidé sud-américain. Cette ressemblance est probablement souhaitée pour une meilleure mémorabilité.
De ce choix de nom est dérivé celui d'Alpaca, l'agent conversationnel basé sur LLaMA, car l'alpaga (alpaca en anglais) est un autre camélidé d'Amérique du Sud.
La version initiale a été publiée en février 2023, en quatre tailles différentes : 7, 13, 33 et 65 milliards de paramètres. À l'origine, seuls la méthodologie, l'architecture des modèles et les résultats expérimentaux furent publiés. Seuls certains chercheurs qui en ont fait la demande peuvent avoir accès au modèle.
Le 3 mars 2023, une semaine après la publication de la méthodologie et de l'architecture, un fichier torrent contenant l'intégralité du modèle est publié sur 4chan.
En juillet 2023, Meta publie une deuxième version, en trois tailles différentes cette fois: 7B, 13B et 70B. La version en 34B a été entrainé par Meta également mais dû à un manque de temps, ils n'ont pas pu publier ce modèle. L'architecture est sensiblement la même mais l'entrainement a été réalisé à partir d'un corpus environ 40% plus volumineux. Cette-fois, Meta publie elle-même les paramètres dès la sortie du modèle.
Avec la publication de Llama 2, Meta publie Llama 2-Chat, une version de Llama optimisée pour les dialogues. Trois versions du modèle sont disponibles: 7B, 13B et 70B.
Peu de temps après, en août 2023, Meta dévoile Code Llama et ses variations Code Llama Instruct et Code Llama Python[10]. Ces modèles sont basés sur Llama 2 et ajustés finement sur du code. Ils sont d'abord disponibles en open source en version 7B, 13B et 34B, puis le 29 janvier 2024 une version en 70B est également publiée[11].
Le 18 avril 2024, Meta lança Llama 3 en version 8 et 70 milliards de paramètres. Ces modèles furent pré-entraînés sur environ 15 billions de jetons de texte provenant de « sources disponibles publiquement »[12], les modèles d'instructions étant fine-tunés sur « des ensembles de données d'instructions disponibles publiquement, ainsi que sur plus de 10 millions d'exemples annotés par des humains ». Meta prévoit de sortir des modèles multimodaux, des modèles capables de converser dans plusieurs langues, et des modèles avec des fenêtres de contexte plus larges. Une version de 405 milliards de paramètres est annoncée à la mi-2024[13].
Trois sous-versions de Llama 3 sont ensuite lancées par Meta :
Avec Llama 3.2, Meta introduit deux modèles multimodaux : Llama 3.2 90B et 11B. Le groupe sort aussi deux premiers mini-modèles, 1B et 3B, destinés à être utilisés sur des terminaux légers (ordinateurs portables ordinaires et smartphones).
LLaMA se présente comme un modèle ouvert, mais ni le code d'entrainement ni les données d'entrainement ne le sont, ce qui fait préférer le terme de « poids ouverts »[18],[19]. Le dépôt contient le code source d'inférence et de la documentation (guide de l'utilisateur, guide de l'utilisateur responsable et model card) permettant une bonne utilisation du modèle. Utiliser LLaMA implique d'accepter les termes de la licence de LLaMA qui notamment interdit certains cas d'utilisation du modèle[20]. En respectant les termes de la licence, il est possible d'utiliser, de reproduire, de distribuer, de copier, de créer des œuvres dérivées et d'apporter des modifications aux différents composants de LLaMA mis à disposition, y compris pour une activité lucrative.
Tout comme tous les autres grands modèles linguistiques actuels (août  2024), il nécessite que ces paramètres (poids) soient stockés dans la mémoire vive, pour s'exécuter à une vitesse raisonnable, ce qui rend les grands modèles souvent inaccessibles pour des ordinateurs personnels. Certains services en ligne proposent de passer par leur serveur pour utiliser LLaMA.
Après l'annonce d'un partenariat entre Meta et Reuters pour l'utilisation des contenus de l'agence dans les chatbots Meta AI, basés sur Llama, il n'était pas clair si ces articles allaient intégrer le corpus de formation de Llama, ou seulement être utilisés comme sources (en direct) pour répondre à des requêtes spécifiques (actualité, politique, économie...)[21].
